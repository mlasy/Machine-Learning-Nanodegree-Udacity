<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>capstone_report_template</title>
<link rel="stylesheet" href="https://stackedit.io/res-min/themes/base.css" />
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body><div class="container"><h1 id="machine-learning-engineer-nanodegree">Machine Learning Engineer Nanodegree</h1>



<h2 id="telstra-network-disruptions">Telstra Network Disruptions</h2>

<p>Jeremias Binder  <br>
June 2nd, 2017</p>



<h2 id="i-definition">I. Definition</h2>



<h3 id="project-overview">Project Overview</h3>

<p>Telstra is australias biggest telecommunications and media company with an annual revenue of over 20 billion USD (A$27.1 billion).</p>

<p>In a recent Kaggle competition, Telstra challenged people to predict the severity of service disruptions on their network. Read the problem description provided by the competition hosts:</p>

<blockquote>
  <p>“Telstra is on a journey to enhance the customer experience - ensuring <br>
  everyone in the company is putting customers first. In terms of its <br>
  expansive network, this means continuously advancing how it predicts <br>
  the scope and timing of service disruptions. Telstra wants to see how <br>
  kaggle users would help it drive customer advocacy by developing a <br>
  more advanced predictive model for service disruptions and to help it <br>
  better serve its customers.” </p><p>(Telstra Network Disruptions. (2016). Retrieved and edited June 12, 2017,  from the <a href="https://www.kaggle.com/c/telstra-recruiting-network/data">competitions page</a>).</p>
</blockquote>

<p>The data used in the competition is provided by Telstra. Service logs and data from their network nodes were prepared, anonymised and are available on <a href="https://www.kaggle.com/c/telstra-recruiting-network/data">Kaggle</a>.</p>

<p>The competition ended at 2/29/2016, the winner was a user called ‘Mario Filho’. In total, 974 teams participated in the competition. </p>

<p>One of the reasons i choose this project as my capstone project for the Machine Learning Nanodegree at Udacity, is that the company i am currently working at, the sovanta AG in Heidelberg, Germany, has some projects running in the domain of predictive maintenance.</p>



<h3 id="problem-statement">Problem Statement</h3>

<p>The problem we are about to solve, is to minimize the reaction time to interruptions in Telstras network. Long reaction times lower customer satisfaction in the long run and can therefore be costly to Telstra.  <br>
A model, that can predict accurately the network failures in advance, would be very valuable to Telstra and its customers.</p>

<p>The problem right now is, that Telstra has no good estimation on when one of their nodes will fail. They might have clues (certain nodes reporting an error), but no further conclusions are drawn from this data.</p>

<p>A  solution to this problem is a table, which returns us the probability for the fault severity labels (0,1,2) of any given network incident with its location and ID. With an input like this:</p>

<table>
<thead>
<tr>
  <th>id</th>
  <th></th>
  <th>location</th>
  <th align="center">event <br>type 12</th>
  <th align="center">log <br>feature 35</th>
  <th align="center">resource <br> type</th>
  <th align="center">…</th>
</tr>
</thead>
<tbody><tr>
  <td>62093</td>
  <td></td>
  <td>129</td>
  <td align="center">1</td>
  <td align="center">74</td>
  <td align="center">81</td>
  <td align="center">…</td>
</tr>
<tr>
  <td>58261</td>
  <td></td>
  <td>814</td>
  <td align="center">1</td>
  <td align="center">0</td>
  <td align="center">29</td>
  <td align="center">….</td>
</tr>
</tbody></table>


<p>we expect the output to be like this:</p>

<table>
<thead>
<tr>
  <th>id</th>
  <th></th>
  <th>fault <br>severity 0</th>
  <th align="center">fault <br>severity 1</th>
  <th align="center">fault <br>severity 2</th>
</tr>
</thead>
<tbody><tr>
  <td>62093</td>
  <td></td>
  <td>0.980095</td>
  <td align="center">0.09974</td>
  <td align="center">0.000155</td>
</tr>
<tr>
  <td>58261</td>
  <td></td>
  <td>0.321231</td>
  <td align="center">0.059807</td>
  <td align="center">0.61892</td>
</tr>
</tbody></table>


<p>In order to obtain this output, a classifier will be trained and used to predict the label given incident data. In the following chapters, i will describe how the input data has to be arranged and fed to the classifier, to get the output we want.</p>

<p>Since the input information is digitally obtained, each error message can be put in a certain category and is distinct. Also, it’s a future prediction, it’s easily verifiable: After the event is predicted, the actual time and place can be observed and the degree to which the prediction is correct can be verified.</p>

<h3 id="metrics">Metrics</h3>

<p>The thing Telstra is interested in, is when and where their nodes are likely to fail. The quality of the prediction therefore matters:  <br>
To determine the quality of such a model the multi-class logarithmic loss is used. Each data row has been labeled with one true class, which represents the severity of the incident (an incident with label ‘0’ means, there is no issue). For each row,  a set of predicted probabilities is submitted (one for every fault severity). The formula is then,</p>



<p><script type="math/tex; mode=display" id="MathJax-Element-1"> logloss = - {1\over N} \sum_{i=1}^{N} {\sum_{j=1}^{M}}  {y_{ij}  log (p_{ij})},</script></p>

<p>where N is the number of rows in the test set, M is the number of fault severity classes,  <script type="math/tex" id="MathJax-Element-2"> log </script> is the natural logarithm, <script type="math/tex" id="MathJax-Element-3"> y_{ij} </script> is 1 if observation <script type="math/tex" id="MathJax-Element-4">i</script> belongs to class <script type="math/tex" id="MathJax-Element-5">j</script>  and <script type="math/tex" id="MathJax-Element-6">0</script> otherwise, and <script type="math/tex" id="MathJax-Element-7">p_{ij}</script> is the predicted probability that observation <script type="math/tex" id="MathJax-Element-8">i</script> belongs to class <script type="math/tex" id="MathJax-Element-9">j</script>. <br>
Or in layman terms: The lower the sum of wrongly predicted severities, the lower the logloss. Participants with a lower logloss on the testset get ranked higher on the public leaderboard.  <br>
Scoring a low logloss on the testset is important, since the model might overfit on the trainset.</p>

<p>Why does the multilogloss makes sense here? <br>
The output of our model is the severity of a network issue (“Fault_Severity”). This severity is measured in three integer categories from zero to two. Meaning, we have exactly three labels.  <br>
But: Our model will give us predictions in the form of a probability distribution (i.e. 0: 0.212, 1: 0.573, 2:0.215). The most likely category in this example would be the second one with a chance of 0.573. If we were to measure the output label (in this example “1”), some valuable information about the quality of our model is discarded. </p>

<p>Now, intuitively speaking:  log-loss is the cross entropy between the distribution of the true labels and the predictions. We use it to gauge the “extra noise” that comes from using a predictor as opposed to the true labels. By minimizing the cross entropy, one maximizes the accuracy of the classifier.</p>



<h2 id="ii-analysis">II. Analysis</h2>



<h3 id="data-exploration">Data Exploration</h3>

<p>Lets take first glance at the data, which comes in six files:</p>

<p>train.csv - the training set for fault severity  <br>
test.csv - the test set for fault severity  <br>
event_type.csv - event type related to the main dataset  <br>
log_feature.csv - features extracted from log files  <br>
resource_type.csv - type of resource related to the main dataset  <br>
severity_type.csv - severity type of a warning message coming from the log</p>

<p>All the files have one attribute, that connects them all together: The column named ‘id’. Note that the ‘id’ doesn’t have the same property as a key we might now from relational databases: Sometimes one id is listed several times in one column.</p>

<p>After quickly scrolling through the data in MS Excel, i decided to do the following: <br>
In order to just process numeric data, i dropped the strings from all the csv files containing the description (‘event_type ‘, ‘log_feature ‘, ‘resource_type’) manually with the excel replace function.</p>

<table>
<thead>
<tr>
  <th>id</th>
  <th align="center">event_type</th>
</tr>
</thead>
<tbody><tr>
  <td>62093</td>
  <td align="center"><del>event_type</del> 15</td>
</tr>
</tbody></table>


<p>The thing i did then was calculating basic statistics of the data from the files to get a good first understanding. <br>
What i found out was:</p>

<ul>
<li><p>Most of the interruptions in the <em>train</em> data are just a temporary network glitch ( Fault <br>
Severity = 0), but 1 and 2 do seem to cause problems quite frequently <br>
(around 35% of the time). </p></li>
<li><p>The <em>event types</em> 11,35 and 34, 15 and 2 seem <br>
occur a lot together with a network incident</p></li>
<li><p><em>Resource types</em> 8 and 2 are the most prevalent. There is a significant gap <br>
between these two resources and the rest.</p></li>
<li><p><em>Severity type</em> of warning messages 1 and 2 seem to be the most frequent ones.</p></li>
<li><em>Log features</em> is actually tricky to deal with: we have the ‘id’ column, then the ‘log feature’ column and a ‘volume’ column, which indicates how often a ‘log feature’ appeared with an network incident. The fact that there are 386 different ‘log features’ became a real sticking point for this problem. </li>
</ul>

<p>Note that this is just a univariant analysis of the features provided in the single files. The initial plan was to provide a multivariant analyis of the data, but this became almost impossible, since the data is quite sparse.</p>

<p>So the challenge in the first place was to merge the files into one coherent frame to work with. This turned out to be more difficult than expected, since the the <em>log_feature</em> table contained 453 categorical values, which couldn’t be merged easily together with the ids of the other files.</p>

<p>Also, each id usually had just a few features from <em>log_feature</em>, so i decided to one-hot encode the information into the frame. Actually, i tried two versions of one-hot-encoding to solve this problem: <br>
At first, i did a binary one-hot-encoding and discarded the <em>volume</em> information of the features, then i tried something else and used the <em>volume</em> value of each feature instead of just a one. </p>

<p>I ended up with a dataframe with a total of 453 features, which are quite difficult to visualize even pandas</p>

<pre><code>print train.head(3)
</code></pre>

<p>prints out a quite extensive output:</p>

<p><img src="https://image.ibb.co/kfwHH5/Screen_Shot_2017_07_31_at_12_22_08.png" width="600"></p>

<p>Note that the log_feature columns contain a lot of zero values. This makes the dataset as a whole quite sparse, i assume we would have difficulties using a strong learner with this problem.</p>


<h3 id="exploratory-visualization">Exploratory Visualization</h3>

<p>As already explained above, due to the sparse nature of the data, a multivariate analysis of the data is not easy to provide. However, i plotted the features in histograms, which seems like a good entry point for further discussions. </p>

<p><img src="https://image.ibb.co/df4Jk5/fig.png" alt="enter image description here" title=""></p>

<p>The histograms shown above give an impression on how sparse the data actually is: <br>
While some features are distributed across all issues (Severity, Severity type) others occur unevenly. After reading about internet providers service disruptions on the internet, these graphs made much more sense to me: A guy described that usually, if a node has a issue with one feature at a time, this usually doesn’t break the connection. This happens only if a certain combination of issues occur at the same time. </p>

<p>There are few facts about these graphs that really stick out:</p>

<ul>
<li>As we can see, most of the interruptions are just a temporary network glitch ( Fault Severity = 0), but 1 and 2 do seem to cause problems quite frequently (around 35% of the time).</li>
<li>The event types 11,35 and 34, 15 and 2 seem occur a lot together with <br>
a network incident.</li>
<li>The resource types 8 and 2 are used most. There is a significant gap <br>
between these two resources and the rest.</li>
<li>The severity type of warning messages 1 and 2 seem to be the most <br>
frequent ones.</li>
<li>The log features behave a little different here: We have a bunch of different features, which occur in a different Frequency (Volume). The two graphs above show just how often a given feature appears with an issue. Since the feature with the largest volume occurs 1350 times, the graph on the bottom left corner is highly skewed.</li>
</ul>



<h3 id="algorithms-and-techniques">Algorithms and Techniques</h3>

<p>So, after merging the files in one single frame, i could finally get started with my very first model. Reading through some of the forums on the web and in specific kaggle, i decided to take a closer look on the xgboost algorithm.</p>

<p>The xgboost algorithm is a flexible, performant, and scalable gradient boosting algorithm, which gained a lot of popularity on recent kaggle competitions. </p>

<p>So what exactly is a gradient boosting algorithm? <br>
A gradient boosting algorithm can be seen as sort of an extension to a regular prediction technique.  The underlying algorithm (in most of the cases decision trees) creates in the first iteration a very simple model, which hits just slightly better than chance. The resulting classifier is called a weak learner. What the xgboost algorithm does, is stacking a bunch of these weak learners to a ensemble model, which then can create a pretty accurate model.</p>

<p>But this is not the only thing, the xgboost algorithm is capable of: <br>
It also weights the different weak learners according to their predictive power. If some learner would predict the true label really accurately, xgboost places a higher weight on it in the final model. In other words: xgboost is trying to minimize the error created by the learners. So, gradient boosting can be seen as a form of the gradient descent algorithm.</p>

<p>Lets have a look on the most important default parameters set in our xgboost classifier ( or read the <a href="https://github.com/dmlc/xgboost/blob/master/doc/parameter.md">full list</a>):</p>

<ul>
<li>eta [default=0.3, alias: learning_rate]: The learning rate of algorithm, Makes the model more robust by shrinking the weights on each step.</li>
<li>gamma [default=0, alias: min_split_loss]: A node is split only when the resulting split gives a positive reduction in the loss function. Gamma specifies the minimum loss reduction required to make a split.</li>
<li>max_depth [default=6]: This describes the maximum depth of a decision tree. The parameter is used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample.</li>
<li>min_child_weight [default=1]: here we define the minimum sum of weights of all observations required in a child node of a DT. Its also a measure to prevent overfitting, it avoids relations which might be highly specific to a certain sample.  </li>
</ul>

<p>The xgboost algorithm  creates a bunch of weak learners, which perform very poorly (just slightly above chance) on their own. But then comes boosting, in which we start by looking over the training data and generate some distributions, then find some set of Weak Learners (classifiers) with low errors, and each learner outputs some hypothesis, <script type="math/tex" id="MathJax-Element-327"> {H_{x}} </script>. This generates some <script type="math/tex" id="MathJax-Element-328">Y </script>(class label), and at the end combines the set of good hypotheses to generate a final hypothesis.</p>

<h3 id="benchmark">Benchmark</h3>

<p>To determine the quality of the model the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html">multiclass logarithmic loss function</a> is used in the kaggle competition. <br>
While users have a trainset for their own use, kaggle uses a hidden testset to prevent people from overfitting. <br>
Depending on how low a participant scores using the multiclass log loss function on this hidden testset, the leaderboard ranking is determined.</p>

<p>This leaderboard ranking (the private and therefore final ranking) will be used as a benchmark in this project.</p>

<p>To get a feeling on what score to expect:  <br>
The first place on the Telstra leaderboard, a user called Mario Filho, scored a log loss of 0.3954. Since this is my first kaggle problem, I will aim for at least 0.51, since this will put me in the top 33% of the participants.</p>

<p>A benchmark of 0.51 is both realistic for a kaggle novice like me and good enough to achieve a reasonable output (relative to the competition, the Telstra team doesn’t provide us with information on what a good prediction actually would be).</p>

<p>A graph which displays the log loss distribution of the competition will be provided in the final chapter of the project.</p>

<h2 id="iii-methodology">III. Methodology</h2>



<h3 id="data-preprocessing">Data Preprocessing</h3>



<h4 id="1-merging-the-data">1. Merging the data.</h4>

<p>As explained in the ‘Data Exploration’ Section, the problem with our dataset is, that the length of the different data files attributes have different length. Not every id in the one table corresponds to every id in the other tables. Some tables vary in length. In order to fit the data to the xgboost classifier, the dataframe first has to be put in shape.</p>

<p>To unify this information, i decided to one-hot encode all the features. While this was quite straightfoward with <em>events</em>, <em>severity</em>, and <em>resource type</em>, i had decided to change plans with <em>log features</em> at first: <br>
I decided to drop the information of the <em>volume</em> column and make <em>log feature</em> binary.</p>

<p>Say for a given <em>id</em> the volume of feature 2 is 7, while log features 1-n are all zero. You can see the pure “one-hot encoded” approach in the first row, and the “volume-hot-encoded” approach in the second row. <br>
<br></p>

<table>
<thead>
<tr>
  <th>approach</th>
  <th></th>
  <th>id</th>
  <th align="center">log feature 1</th>
  <th align="center">log feature 2</th>
  <th align="center">…</th>
  <th align="center">log feature n</th>
</tr>
</thead>
<tbody><tr>
  <td>one-hot encode</td>
  <td></td>
  <td>62093</td>
  <td align="center">0</td>
  <td align="center">1</td>
  <td align="center">…</td>
  <td align="center">0</td>
</tr>
<tr>
  <td>volume-hot encode</td>
  <td></td>
  <td>62093</td>
  <td align="center">0</td>
  <td align="center">7</td>
  <td align="center">…</td>
  <td align="center">0</td>
</tr>
</tbody></table>


<p><br></p>

<p>Now i had all the features one hot encoded in different tables. <br>
Time, to unify them into one table. In order to do so, i merged the files one by one into the ‘train’ pandas frame. </p>

<p>I merged the ‘train’ frame with the ‘severity’ frame on their id, by using keys from the train frame, similar to a SQL left outer join. The operation preserves the key order.</p>

<p>I finally ended up with a 7381x453 dataframe, which contained all possible features, one-hot encoded. <br>
So here’s a simplified version of how the table looks after all the operations. Note that it containts 453 columns (shortened here with 1…n)<br><br> </p>

<table>
<thead>
<tr>
  <th>id</th>
  <th></th>
  <th>severity <br>type 1 … n</th>
  <th align="center">event <br>type 1 … n</th>
  <th align="center">log <br>feature 1 … n</th>
  <th align="center">resource <br> type 1 … n</th>
  <th align="center">fault <br>severity</th>
</tr>
</thead>
<tbody><tr>
  <td>62093</td>
  <td></td>
  <td>1</td>
  <td align="center">0</td>
  <td align="center">1</td>
  <td align="center">1</td>
  <td align="center">0</td>
</tr>
<tr>
  <td>58261</td>
  <td></td>
  <td>1</td>
  <td align="center">0</td>
  <td align="center">0</td>
  <td align="center">…</td>
  <td align="center">2</td>
</tr>
<tr>
  <td>…</td>
  <td></td>
  <td>…</td>
  <td align="center">…</td>
  <td align="center">…</td>
  <td align="center">…</td>
  <td align="center">…</td>
</tr>
<tr>
  <td>28413</td>
  <td></td>
  <td>0</td>
  <td align="center">1</td>
  <td align="center">0</td>
  <td align="center">0</td>
  <td align="center">1</td>
</tr>
</tbody></table>


<p>This dataset is now ready for a first fitting iteration with xgboost.</p>

<h3 id="implementation">Implementation</h3>

<p>Now that i finally got the dataframe set up, we’re ready to run the first iteration of our fault severity prediction. <br>
 As described above, i choose the xgboost algorithm as classifier. Lets split our dataset into a train- and testset, and see what logloss we can achieve with this rough first draw:</p>

<pre><code>test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=test_size, random_state=7)
model_1 = xgboost.XGBClassifier(eval_metric='mlogloss', max_depth = 5)
model_1.fit(X_train, y_train.values.ravel())
</code></pre>

<p>Note that the initial parameters for our classifier are the default settings, i just changed <em>max_depth</em> to <em>5</em>, since the default value of <em>3</em> appeared very small for such a sparse dataset. Parameter tuning and model improvement will be the topic of the refinement chapter.</p>

<p>The moment of truth came, the classifier accepted the frame without an error and fitted the first classifier. </p>

<pre><code>   from sklearn.metrics import log_loss
   y_pred = model_1.predict_proba(X_test)
   print("Logloss: %.3f" % log_loss(y_test,y_pred))
   ----
   Logloss: 0.584
</code></pre>

<p>A value of 0.584 on the personal testset and 0.578 on the kaggle board is a quite acceptable value for the first submission without any tuning. </p>



<h3 id="refinement">Refinement</h3>

<p><strong>1. Feature importances</strong></p>

<p>The initial model is now set up, and gives us a stable result we can further build upon.  <br>
As in the preprocessing chapter described, there are a lot of attributes we included, resulting in a very sparse dataset. In order to improve the result, it is obvious to me, that the feature space needs to be reduced.</p>

<p>Luckily, xgboost provides us a simple tool for that:</p>

<pre><code>model.feature_importances
</code></pre>

<p>returns us a list of how each feature contributed to the prediction. Since we have more than 400 features, it could makes sense that not all these features contribute equally to the prediction. Some might even have a zero impact. <br>
 Since this creates only noise and makes further progress harder, it does make sense to remove them.</p>

<p>So i tested the model with different thresholds (meaning a different amount of features) and found out, that i could reduce the feature space from n=452 down to n= 133, with just a very slight increase in the log loss. </p>

<p><strong>2. Feature engineering</strong> <br>
Since i tried very hard to decrease the log loss by feature reduction, but couldn’t succeed eventually, i tried to take a shot for feature engineering. Maybe i can deduce new information, based on a logic or combination of already existing data. </p>

<p>After reading <a href="http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/">this</a> interesting post about proper feature engineering, i took a closer look on the data and crafted two new features:</p>

<ul>
<li>a ranking sorted by severity type (0.0 for the sample with the lowest int, 1.0 for the highest)</li>
<li>a counter for the location (how often a particular location occurred)</li>
</ul>

<p>This probably made the biggest difference in the prediction process. After parameter tuning (see next paragraph) i brought down the log loss to just above 0.50.</p>

<p>Note: If i had to continue working on the project to improve the log loss, more detailed feature engineering would probably the only way to improve significantly.</p>

<p><strong>3. Tuning Parameters</strong> <br>
Finally, after deciding on which features to use, i decided to tune my algorithm by choosing the right parameters for the xgboost algorithm. At the beginning i didn’t expect it to be such a time-, and calculation intense process. Luckily, a friend from work had a AWS-coupon for me, so this allowed me to do the computations much quicker.</p>

<p>After i read this <a href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/">article</a> on parameter tuning with xgboost, i decided to tune the following parameters (max. two at a time):</p>

<ul>
<li>{‘num_boosting_rounds’}: numbers of trees used.</li>
<li>{‘max_depth’ , ‘min_child_weight’ }: <br>
The maximum depth of a tree and the minimum sum of weights of all observations required</li>
<li>{‘gamma’}: specifies the minimum loss reduction required to make a split</li>
<li>{‘subsample’, ‘colsample_bytree’}: <br>
The fraction of observations to be randomly samples for each tree and fraction of columns to be randomly  samples for each tree.</li>
</ul>

<p>I expected the most impact of the to come from the ‘max_depth’ and ‘num_boosting_rounds’ variable, since they have the biggest impact on over- or underfitting.</p>

<p>I ended up with the following parameters (before/after tuning):</p>

<ul>
<li>num_boosting_rounds=100/488,  </li>
<li>max_depth=5/5</li>
<li>min_child_weight=1/1</li>
<li>gamma = 0/0.8</li>
<li>subsample=1/0.9</li>
<li>colsample_bytree=1/0.7</li>
</ul>

<p>After running the long and processing power intense tuning i could improve the log loss from 0.58323 down to 0.50050 (private kaggle leaderboard).</p>

<p>This is not a huge leap, but as i already mentioned, the biggest reduction in the log loss comes in this problem from choosing and engineering the right set of features.</p>

<p>Here you can see how i did over time:</p>

<p><img src="https://image.ibb.co/g8SeAQ/fig32.png" alt="Improvement over time" title=""></p>

<p>The biggest improvement was definitely after tuning num_boosting_rounds ( ~0.04). 100 rounds were just not enough. The other parameters improved the score just slightly (or not at all).</p>

<p>Using a too high number (&gt;6) for max_depth resulted in overfitting, so i just kept it at around 5. <br>
Since i used cross validation for parameter tuning, I’m confident about their robustness in the model.</p>
<div style="page-break-before:always">&nbsp;</div>
<h2 id="iv-results">IV. Results</h2>



<h3 id="model-evaluation-and-validation">Model Evaluation and Validation</h3>

<p>After i scored 0.50050 on the private kaggle leaderboard i decided to stop further engineering on the project. <br>
I validated my results with a part of my own trainset (25%) and on the kaggle submission board. Since the kaggle validation data is not visible to the participant, it’s safe to assume, that the model can be trusted and actually performs well on unseen data.</p>

<p>While i did the grid-search on the AWS-instance, i did in fact overfit at one point, when i set the ‘max_depth’ too high. But i quickly catched this error while testing the model on my own testset.</p>

<p>I was very happy to see the score of 0.50050 appear on the kaggle submission board. This was much more than i expected in my benchmark.  This score would put me in the top 19%, so i beat my benchmark. </p>

<p>I have the impression that i chose an appropriate algorithm and covered the most important steps to achieve a good solution compared to the initial benchmark while solving the network disruption problem.  <br>
To get a understanding of how good the solution actually is: <br>
The chance of being right by chance would be 33% in this problem, so an improvement up to approx. 66% sounds not too bad. Although this value is not very reliable, i think it gives the telstra a good opinion on how to rate a network incident.</p>

<p><img src="https://image.ibb.co/d6b9Ma/log_loss_curve.png" alt="Improvement over time" title=""></p>

<h3 id="justification">Justification</h3>

<p>The results from the final model are improved by 0.08 (from 0.58 down to 0.50), or around 16%. For comparison: The first place on the kaggle leaderboard would have improved by around 33% by this measure.  <br>
The biggest change in log loss was achieved through implementing the ranks on the features with the highest feature importance.</p>

<p>Feature selection, feature engineering and parameter tuning have been discussed thoroughly, at this point its safe to say that a satisfactory solution has been found. </p>

<p>However, with more effort into feature engineering, i believe this solution could be further improved.</p>

<p>The final solution has the following major differences compared to the initial solution:</p>

<ul>
<li>the xgboost parameters have been tuned</li>
<li>Features such as rank have been added</li>
</ul>

<p>All the other things done in the notebook can be considered as experiments, which attempted to improve the score but eventually failed to do so.</p>

<div style="page-break-before:always">&nbsp;</div>

<h2 id="v-conclusion">V. Conclusion</h2>


<h3 id="free-form-visualization">Free-Form Visualization</h3>

<p>At one point, i tried to reduce the size of the total dataset by filtering out unimportant features (feature selection). <br>
In the end, this method didn’t really help me to improve the log loss, although in some cases i think it might be quite helpful to reduce the dimensions of the dataset.</p>

<p><img src="https://image.ibb.co/gtoeMa/fig32.png" alt="Improvement over time" title=""></p>

<p>Although this method even lowered the log loss slighlty on the personal set, it failed to do so on the kaggle test set. Thats why i abandoned feature selection at the end.</p>

<h3 id="reflection">Reflection</h3>

<p>The project can be summarized in four steps:  <br>
1. Feature preprocessing <br>
2. Fitting <br>
3. Predicting <br>
4. Improving</p>

<p>The first step was to get a quick first solution that works. That was achieved by throwing all the available information into a model that seemed to be fitting to this kind of problem. So after the data was merged into one set, i fitted it immediately, without removing or adding any information. Then i checked the result and improved the solution gradually from there on. </p>

<p>But why not working slowly up to one “perfect solution”? <br>
In my opinion, it can be very dangerous to spend a lot of time on one particular part of the model building process. One might easily get lost or run out of time without providing a basic solution. Thats the reason i was a big fan of gradual improvement rather than building the right model right from the bottom up.</p>

<p>The thing i had the most trouble with was the fact, that there were so many features, and i couldn’t find a good way to visualize them to get the most information out of it. <br>
Also i had no domain knowledge, or in general any idea about network disruptions and how they occur. This made it kind of difficult to extract meaningful information out of the provided features. In the real world, i would prefer to have someone explaining the problem and the relations between the features to get a feeling on how the system works in general. This would make feature engineering (the thing that made the biggest improvement in the algorithm) a lot easier.</p>

<p>I really liked working with the xgboost algorithm. It seems to me, that this algorithm fits very good on problems with sparse data. Also, there is a great community with great ideas on kaggle, github and stackoverflow. Its very likely to find help out in the internet if one needs more information about a specific feature of the xgboost package.</p>



<h3 id="improvement">Improvement</h3>

<p>If i had to further improve the algorithm, i would definitely spent more time on feature engineering and less time on tuning parameters. This would maybe even enable me to get a score that is ranked in the top 100 of the competition. There are many creative ways to extract informations out of all the attributes and i consider it as an art to really think creatively on what features to construct.  <br>
Actually, working on this project made me curious to further dig into literature which covers the topic of feature engineering.  <br>
Also, i wish i knew ways to better visualize the data. This somehow is related to feature engineering, since visualization can really give new inspirations to what feature to engineer in the next step.</p>

<p>Lastly, i wish that i kept my jupyter notebook cleaner, reused functions more often and parameterize them instead of rewriting whole blocks. In the end i had trouble navigating to the whole book and finding what i was looking for. It also took longer to change certain points in the prediction pipeline. This would make it easier for third persons to understand as well.</p></div></body>
</html>